{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    #Funición a evaluar\n",
    "    a = (np.e**(-x[0]**2 - x[1]**2))*x[0]\n",
    "    return a\n",
    "\n",
    "\n",
    "def grad(x):\n",
    "    \"\"\" Retorna gradiente f\"\"\"\n",
    "    list1 = [1-2*x[0]**2, -2*x[0]*x[1]]\n",
    "    descenso = np.array(list1)*math.e**(-x[0]**2 - x[1]**2)\n",
    "    return descenso\n",
    "\n",
    "\n",
    "def hessiano(x):\n",
    "    \"\"\"Evalua la matriz Hessiana, ingresar derivadas\"\"\"\n",
    "    axax = (2*x[0]*((2*x[0]**2)-3))*math.e**(-(x[0]**2) - (x[1]**2))\n",
    "    ayay = (2*x[0]*((2*x[1]**2) - 1))*math.e**(-(x[0]**2) - (x[1]**2))\n",
    "    axay = 2*(2*x[0]**2 - 1)*x[1]*math.e**(-x[0]**2 - x[1]**2)\n",
    "    # return axay\n",
    "    return np.array([\n",
    "        [axax, axay],\n",
    "        [axay, ayay]\n",
    "    ])\n",
    "\n",
    "\n",
    "def dirgrad(x):\n",
    "    \"\"\"Retorna la dirección del gradiente p\"\"\"\n",
    "    vgrad = grad(x[0], x[1])\n",
    "    magGrad = np.sqrt(vgrad.dot(vgrad))\n",
    "    p = -vgrad/magGrad\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculos de phi\n",
    "def phiAlpha(x0, alpha, p):\n",
    "    paX = x0 + p * alpha\n",
    "    return f(paX)\n",
    "\n",
    "\n",
    "def phipAlpha(x0, alpha, p):\n",
    "    x = x0 + alpha * p\n",
    "    vgrad = grad(x)\n",
    "    return (np.dot(vgrad, p))\n",
    "\n",
    "\n",
    "def phipp(x0, alpha, p):\n",
    "    x = x0 + alpha * p\n",
    "    ahess = hessiano(x)\n",
    "    return np.dot(np.dot(ahess, p), p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiente Conjugado NL\n",
    "def newton(xo, p, ao, itmax=100, tol=1e-12):\n",
    "    k = 0\n",
    "    # ak = 0\n",
    "    while abs(phipAlpha(xo, ao, p)) > tol:\n",
    "        phiap = phipAlpha(xo, ao, p)\n",
    "        phiapp = phipp(xo, ao, p)\n",
    "        ak = ao - phiap/phiapp\n",
    "        # print(f\"\\t {k}, {ak}\")\n",
    "        k = k+1\n",
    "        ao = ak\n",
    "        if k >= itmax:\n",
    "            print(\"Iteraciones exedidas\")\n",
    "            break\n",
    "    return ak\n",
    "\n",
    "\n",
    "def gradientesConjugados(x0, flavor=\"FR\", k=0, tol=1e-6):\n",
    "    beta = 0\n",
    "    p = -grad(x0)\n",
    "    print(\"k, fx, x0, alpha, beta, \")\n",
    "    while np.linalg.norm(grad(x0)) >= tol:\n",
    "        alpha = newton(x0, p, 0)\n",
    "        xi = x0 + alpha*p\n",
    "        gradxi = grad(xi)\n",
    "        gradx0 = grad(x0)\n",
    "        if flavor == \"FR\":\n",
    "            beta = np.dot(gradxi, gradxi)/np.dot(gradx0, gradx0)\n",
    "        elif flavor == \"PR\":\n",
    "            beta = np.dot(gradxi, (gradxi - gradx0)) / \\\n",
    "                (np.linalg.norm(gradx0))**2\n",
    "        elif flavor == \"PR+\":\n",
    "            beta = np.dot(gradxi, (gradxi - gradx0)) / \\\n",
    "                (np.linalg.norm(gradx0))**2\n",
    "            if beta < 0:\n",
    "                beta = 0\n",
    "        elif flavor == \"HS\":\n",
    "            beta = np.dot(gradxi, (gradxi - gradx0)) / \\\n",
    "                np.dot((gradxi - gradx0), p)\n",
    "        p = -gradxi + beta*p\n",
    "        print(k, f(x0), xi, alpha, beta)\n",
    "        x0 = xi\n",
    "        k += 1\n",
    "    return x0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k, fx, x0, alpha, beta, \n",
      "0 -0.3032653298563167 [-0.80901699 -0.19098301] 1.0189657832675951 0.2606987738456306\n",
      "1 -0.4053848723105224 [-0.7403236  0.0210409] 0.906456393822833 -0.0501499460315924\n",
      "2 -0.42776143062150296 [-0.70662349  0.00168334] 0.6510845214090244 0.006702505005436704\n",
      "3 -0.4288805267870102 [-7.07116132e-01  5.49129966e-06] 1.021100376770771 0.002446489970398306\n",
      "4 -0.4288819423924146 [-7.07106782e-01 -1.63286891e-09] 0.6291831056571898 -1.7520436785671866e-05\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-0.5, -0.5])\n",
    "gcnl = gradientesConjugados(x0,\"HS\")\n",
    "# print(gcnl)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
